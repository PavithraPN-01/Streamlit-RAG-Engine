# RAG-Powered Chatbot System ğŸ¤–

This project is a **Retrieval-Augmented Generation (RAG) based chatbot application** built using **Streamlit**, **LangChain**, and **Groq LLMs**.  
It allows users to ask questions based on **PDF documents** or **web-scraped content**.


---

## âš ï¸ Important Note


âš ï¸ ** A valid Groq API key is mandatory to run this application.**

- Users must create a Groq account and generate an API key from:  
  https://console.groq.com/keys
- The application will **not function without a valid API key**
- The API key can be provided in either of the following ways:
  - Add it to a `.env` file as `GROQ_API_KEY`
  - Enter it directly in the Streamlit sidebar at runtime

> ğŸ” For security reasons, API keys are never stored or logged by the application.


## ğŸš€ Features

- ğŸ“„ PDF-based Question Answering
- ğŸŒ Website-based Question Answering using Web Scraping
- ğŸ§  Semantic search using FAISS vector database
- ğŸ” Context-aware responses using RAG
- ğŸ” User-provided Groq API Key
- ğŸ¨ Interactive UI built with Streamlit
- ğŸ³ Docker support for easy deployment

---

## ğŸ› ï¸ Tech Stack

- **Python**
- **Streamlit**
- **LangChain**
- **FAISS**
- **HuggingFace Embeddings**
- **Groq LLM API**
- **BeautifulSoup & Requests (Web Scraping)**
- **Docker**

---

---

## ğŸŒ Web Scraping Module (Separate Explanation)

### ğŸ“ `Web_Scraping/rag_web_scraping.py`

This file **only contains the web scraping logic** and is kept separate for better modularity and reusability.

### ğŸ”¹ Purpose
- Scrapes textual content from a given website URL
- Extracts meaningful text from HTML elements such as:
  - Paragraphs (`<p>`)
  - Lists (`<li>`)
  - Tables (`<td>`)
  - Headings (`<h1>`, `<h2>`, `<h3>`)
- Prepares clean text data that can later be used for:
  - Vector embedding
  - RAG-based question answering
    
---

### ğŸ”¹ Why Separate?
- Keeps scraping logic independent from UI
- Easy to reuse or extend scraping functionality
- Improves code readability and maintainability

> âš ï¸ Note: This file **does not contain LLM, embeddings, or vector database logic**.  
> It strictly focuses on **web data extraction only**.


---


## ğŸ’¬ How It Works (High Level)

- User uploads a PDF or provides a website URL
- Content is extracted and split into smaller text chunks
- Text chunks are converted into embeddings using HuggingFace models
- FAISS stores embeddings for fast semantic retrieval
- Relevant context is fetched based on the user query
- Groq LLM generates accurate answers using Retrieval-Augmented Generation (RAG)


## â–¶ï¸ How to Run the Application

### 3ï¸âƒ£ Run the App

```bash
streamlit run rag_streamlit_app.py
```

### ğŸ³ Run with Docker
Build the Docker image:

```bash
docker build -t rag-chatbot .
```

### ğŸ³ Run the container:

```bash
docker run -p 8501:8501 rag-chatbot
```

### Then --> open your browser and navigate to:

```bash
http://localhost:8501
```






